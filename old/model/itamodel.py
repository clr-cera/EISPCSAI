import cv2, math
import numpy as np
import imutils, dlib
from imutils import face_utils
from skimage import io, color
from matplotlib.path import Path
from scipy.signal import find_peaks, convolve2d


class Segmentation:
    ##### Soure from: https://github.com/Jeanvit/PySkinDetection #####

    def run(self, image):

        #         image = cv2.imread(filename)
        HSV_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
        YCbCr_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCR_CB)
        #         RGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        binary_mask_image = self.color_segmentation(HSV_image, YCbCr_image)
        mask, output = self.region_based_segmentation(image, binary_mask_image)

        return image, mask, output

    def color_segmentation(self, HSV_image, YCbCr_image):

        lower_HSV_values = np.array([0, 40, 0], dtype="uint8")
        upper_HSV_values = np.array([25, 255, 255], dtype="uint8")

        lower_YCbCr_values = np.array((0, 138, 67), dtype="uint8")
        upper_YCbCr_values = np.array((255, 173, 133), dtype="uint8")

        # A binary mask is returned. White pixels (255) represent pixels that fall into the upper/lower.
        mask_YCbCr = cv2.inRange(YCbCr_image, lower_YCbCr_values, upper_YCbCr_values)
        mask_HSV = cv2.inRange(HSV_image, lower_HSV_values, upper_HSV_values)

        binary_mask_image = cv2.add(mask_HSV, mask_YCbCr)
        return binary_mask_image

    def region_based_segmentation(self, image, binary_mask_image):
        image_foreground = cv2.erode(
            binary_mask_image, None, iterations=3
        )  # Remove noise
        dilated_binary_image = cv2.dilate(
            binary_mask_image, None, iterations=3
        )  # Reduce background
        ret, image_background = cv2.threshold(
            dilated_binary_image, 1, 128, cv2.THRESH_BINARY
        )  # set background to 128

        image_marker = np.int32(
            cv2.add(image_foreground, image_background)
        )  # watershed markers
        cv2.watershed(image, image_marker)
        mask = cv2.convertScaleAbs(image_marker)  # convert back to uint8

        # bitwise of the mask with the input image
        ret, image_mask = cv2.threshold(
            mask, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
        )
        output = cv2.bitwise_and(image, image, mask=image_mask)

        return image_mask, output


class SkinTone:
    ##### Source from https://github.com/mattgroh/fitzpatrick17k/blob/main/ita_fitzpatrick_analysis.ipynb

    def __init__(self, modelpath="shape_predictor_68_face_landmarks.dat"):
        self.predictor = dlib.shape_predictor(modelpath)

    def get_slices(self, smooth, shape):

        h, w = smooth.shape
        y, x = np.mgrid[:h, :w]
        points = np.transpose((x.ravel(), y.ravel()))

        # left cheek
        lcheek = []
        lcheek.extend(shape[:6].tolist())
        lcheek.append(shape[31])

        path = Path(lcheek)
        mask = path.contains_points(points)
        mask = mask.reshape(h, w)

        lcheek = np.full(smooth.shape, np.nan)
        lcheek[mask] = smooth[mask]

        # right cheek
        rcheek = []
        rcheek.extend(shape[11:17].tolist())
        rcheek.append(shape[35])

        path = Path(rcheek)
        mask = path.contains_points(points)
        mask = mask.reshape(h, w)

        rcheek = np.full(smooth.shape, np.nan)
        rcheek[mask] = smooth[mask]

        # chin
        chin = []
        chin.extend(shape[6:11].tolist())
        chin.append(shape[57])

        path = Path(chin)
        mask = path.contains_points(points)
        mask = mask.reshape(h, w)

        chin = np.full(smooth.shape, np.nan)
        chin[mask] = smooth[mask]

        return lcheek, rcheek, chin

    def ITA(self, img):

        shape = self.predictor(img, dlib.rectangle(0, 0, img.shape[1], img.shape[0]))
        shape = imutils.face_utils.shape_to_np(shape)

        # ITA MAP
        ita_img, l, b, a = self.get_ita_map(img)
        #     plt.figure()
        #     plt.imshow(ita_img, cmap='coolwarm', vmin=-100, vmax=120)

        # AVERAGE FILTER
        avg = np.full((3, 3), 1 / 9)
        smooth_ = convolve2d(ita_img, avg, mode="same")

        # SKIN SEGMENTATION
        img, mask, output = Segmentation().run(img)
        imgshape = smooth_.shape
        s = smooth_.flatten()
        s[~mask.astype(bool).flatten()] = np.nan
        smooth = s.reshape(imgshape)

        lcheek, rcheek, chin = self.get_slices(smooth, shape)
        #     plt.figure()
        #     plt.imshow(lcheek, cmap='coolwarm', vmin=-100, vmax=120)
        #     plt.imshow(rcheek, cmap='coolwarm', vmin=-100, vmax=120)
        #     plt.imshow(chin, cmap='coolwarm', vmin=-100, vmax=120)

        italst, regionlst = [], []
        for slc in [lcheek, rcheek, chin]:
            f = slc.flatten()
            f = f[~np.isnan(f)]
            if len(f) == 0:
                continue

            values, interv = np.histogram(f, bins=50)
            window = 5
            mav = np.convolve(values, np.ones(window), "same") / window

            peaks, props = find_peaks(mav, mav, prominence=1)
            if len(peaks) == 0:
                ita = np.mean(f)
                italst.append(ita)
            else:
                maxheight_idx = np.argmax(props["peak_heights"])
                ita = interv[peaks[maxheight_idx]]
                italst.append(ita)

        #         plt.figure()
        #         plt.bar(interv[:-1], values, width=1)
        #         plt.plot(interv[:-1],mav)
        #         plt.axvline(ita, 0, 1, color='r')
        #         plt.show()

        px_idx = np.argmax(ita_img.flatten() - np.mean(italst))
        row = max(min(px_idx % ita_img.shape[0], ita_img.shape[0] - 3), 3)
        col = max(min(px_idx // ita_img.shape[0], ita_img.shape[1] - 3), 3)
        region = img[row - 3 : row + 3, col - 3 : col + 3]

        return np.mean(italst), region

    def get_ita_map(self, image):
        """
        Calculates the individual typology angle (ITA) for a given
        RGB image.
        """

        # Convert to CIE-LAB color space
        #         RGB = Image.open(image)
        CIELAB = np.array(color.rgb2lab(image))

        # Get L and B (subset to +- 1 std from mean)
        L = CIELAB[:, :, 0]
        A = CIELAB[:, :, 1]
        B = CIELAB[:, :, 2]
        ITA = np.arctan2(L - 50, B) * (180 / np.pi)

        #         L = np.where(L != 0, L, np.nan)
        #         std, mean = np.nanstd(L), np.nanmean(L)
        #         L = np.where(L >= mean - std, L, np.nan)
        #         L = np.where(L <= mean + std, L, np.nan)
        #         Lmask = np.where(np.isnan(L), 0, 255)

        #         B = np.where(B != 0, B, np.nan)
        #         std, mean = np.nanstd(B), np.nanmean(B)
        #         B = np.where(B >= mean - std, B, np.nan)
        #         B = np.where(B <= mean + std, B, np.nan)
        #         Bmask = np.where(np.isnan(L), 0, 255)

        return ITA, L, B, A

    def ita2str(self, ITA, method="kinyanjui"):

        if method == "kinyanjui":
            if ITA > 55:
                return ("very light", 1)
            elif ITA > 41:
                return ("light 2", 2)
            elif ITA > 28:
                return ("light", 3)
            elif ITA > 19:
                return ("intermediate 2", 4)
            elif ITA > 10:
                return ("intermediate", 5)
            elif ITA <= 10:
                return ("dark", 6)
            else:
                return None

        # Use empirical thresholds
        else:  # Fitzpatrick17k
            if ITA >= 45:
                return ("very light", 1)
            elif ITA > 28:
                return ("light 2", 2)
            elif ITA > 17:
                return ("light", 3)
            elif ITA > 5:
                return ("intermediate 2", 4)
            elif ITA > -20:
                return ("intermediate", 5)
            elif ITA <= -20:
                return ("dark", 6)
            else:
                return None
